{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    input_folder = 'combined_stats'\n",
    "    input_format = 'out'\n",
    "    feature = 'feature'\n",
    "    label = 'label'\n",
    "    X_train = np.loadtxt(\"{}/{}_{}.{}\".format(input_folder, feature, 'training', input_format))\n",
    "    y_train = np.loadtxt(\"{}/{}_{}.{}\".format(input_folder, label, 'training', input_format))\n",
    "    X_val = np.loadtxt(\"{}/{}_{}.{}\".format(input_folder, feature, 'validation', input_format))\n",
    "    y_val = np.loadtxt(\"{}/{}_{}.{}\".format(input_folder, label, 'validation', input_format))\n",
    "    X_test = np.loadtxt(\"{}/{}_{}.{}\".format(input_folder, feature, 'test', input_format))\n",
    "    y_test = np.loadtxt(\"{}/{}_{}.{}\".format(input_folder, label, 'test', input_format))\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1558, 76) (1558,) (106, 76) (106,) (11, 76) (11,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data()\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(76, 38)\n",
    "        self.fc2 = nn.Linear(38, 19)\n",
    "        self.fc3 = nn.Linear(19, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 76)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        y = self.out_act(x)\n",
    "        return y\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1558] loss: 5.970\n",
      "[2,  1558] loss: 5.658\n",
      "[3,  1558] loss: 5.495\n",
      "[4,  1558] loss: 5.345\n",
      "[5,  1558] loss: 5.296\n",
      "[6,  1558] loss: 5.267\n",
      "[7,  1558] loss: 5.243\n",
      "[8,  1558] loss: 5.222\n",
      "[9,  1558] loss: 5.203\n",
      "[10,  1558] loss: 5.187\n",
      "[11,  1558] loss: 5.172\n",
      "[12,  1558] loss: 5.158\n",
      "[13,  1558] loss: 5.146\n",
      "[14,  1558] loss: 5.135\n",
      "[15,  1558] loss: 5.125\n",
      "[16,  1558] loss: 5.114\n",
      "[17,  1558] loss: 5.104\n",
      "[18,  1558] loss: 5.092\n",
      "[19,  1558] loss: 5.081\n",
      "[20,  1558] loss: 5.073\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_training = X_train.shape[0]\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(n_training):\n",
    "        # get the inputs\n",
    "        inputs = X_train_tensor[i][:]\n",
    "        labels = y_train_tensor[i]\n",
    "        labels = labels.view(1, -1)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        # print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_training == (n_training - 1):    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 70\n",
      "Accuracy of the network on the validation: 66 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "n_validation = X_val.shape[0]\n",
    "X_validation_tensor = torch.from_numpy(X_val).float()\n",
    "y_validation_tensor = torch.from_numpy(y_val).float()\n",
    "with torch.no_grad():\n",
    "    for i in range(n_validation):\n",
    "        inputs = X_validation_tensor[i][:]\n",
    "        labels = y_validation_tensor[i]\n",
    "        labels = labels.view(1, -1)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        if outputs.data >= 0.5:\n",
    "            predicted = 1\n",
    "        else:\n",
    "            predicted = 0\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).item()\n",
    "print(total, correct)\n",
    "print('Accuracy of the network on the validation: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1558] loss: 125.727\n",
      "[2,  1558] loss: 125.721\n",
      "[3,  1558] loss: 125.721\n",
      "[4,  1558] loss: 125.721\n",
      "[5,  1558] loss: 125.721\n",
      "[6,  1558] loss: 125.721\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-74f74f74bd71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;31m# print(outputs, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0aeb0f488be4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m76\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lrs = []\n",
    "for i in range(5):\n",
    "    lrs.append(pow(10, -(i + 1)))\n",
    "\n",
    "n_training = X_train.shape[0]\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "n_validation = X_val.shape[0]\n",
    "X_validation_tensor = torch.from_numpy(X_val).float()\n",
    "y_validation_tensor = torch.from_numpy(y_val).float()\n",
    "\n",
    "val_accuracy = []\n",
    "\n",
    "epoch_size = 50\n",
    "for learning_rate in lrs:\n",
    "    net = Net()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "    for epoch in range(epoch_size):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i in range(n_training):\n",
    "            # get the inputs\n",
    "            inputs = X_train_tensor[i][:]\n",
    "            labels = y_train_tensor[i]\n",
    "            labels = labels.view(1, -1)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            # print(outputs, labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % n_training == (n_training - 1):    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_validation):\n",
    "            inputs = X_validation_tensor[i][:]\n",
    "            labels = y_validation_tensor[i]\n",
    "            labels = labels.view(1, -1)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            if outputs.data >= 0.5:\n",
    "                predicted = 1\n",
    "            else:\n",
    "                predicted = 0\n",
    "            correct += (predicted == labels).item()\n",
    "    print(n_validation, correct)\n",
    "    print('Accuracy of the network on the validation: %d %%' % (\n",
    "        100 * correct / n_validation))\n",
    "    val_accuracy.append(correct / n_validation)\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.01, 0.001, 0.0001, 1e-05]\n",
      "[0.4056603773584906, 0.5943396226415094, 0.6698113207547169, 0.6226415094339622, 0.6132075471698113]\n"
     ]
    }
   ],
   "source": [
    "print(lrs)\n",
    "print(val_accuracy)\n",
    "# best lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1558] loss: 5.517\n",
      "Epoch 1 finished Training.\n",
      "Accuracy of the network on the training: 58 %\n",
      "Accuracy of the network on the validation: 59 %\n",
      "[2,  1558] loss: 5.269\n",
      "Epoch 2 finished Training.\n",
      "Accuracy of the network on the training: 58 %\n",
      "Accuracy of the network on the validation: 59 %\n",
      "[3,  1558] loss: 5.224\n",
      "Epoch 3 finished Training.\n",
      "Accuracy of the network on the training: 61 %\n",
      "Accuracy of the network on the validation: 60 %\n",
      "[4,  1558] loss: 5.189\n",
      "Epoch 4 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[5,  1558] loss: 5.144\n",
      "Epoch 5 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[6,  1558] loss: 5.115\n",
      "Epoch 6 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[7,  1558] loss: 5.101\n",
      "Epoch 7 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[8,  1558] loss: 5.098\n",
      "Epoch 8 finished Training.\n",
      "Accuracy of the network on the training: 61 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[9,  1558] loss: 5.107\n",
      "Epoch 9 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[10,  1558] loss: 5.083\n",
      "Epoch 10 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[11,  1558] loss: 5.067\n",
      "Epoch 11 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[12,  1558] loss: 5.077\n",
      "Epoch 12 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 64 %\n",
      "[13,  1558] loss: 5.061\n",
      "Epoch 13 finished Training.\n",
      "Accuracy of the network on the training: 58 %\n",
      "Accuracy of the network on the validation: 59 %\n",
      "[14,  1558] loss: 5.067\n",
      "Epoch 14 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[15,  1558] loss: 5.063\n",
      "Epoch 15 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[16,  1558] loss: 5.056\n",
      "Epoch 16 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 60 %\n",
      "[17,  1558] loss: 5.056\n",
      "Epoch 17 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[18,  1558] loss: 5.046\n",
      "Epoch 18 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[19,  1558] loss: 5.040\n",
      "Epoch 19 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[20,  1558] loss: 5.067\n",
      "Epoch 20 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[21,  1558] loss: 5.046\n",
      "Epoch 21 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[22,  1558] loss: 5.044\n",
      "Epoch 22 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[23,  1558] loss: 5.052\n",
      "Epoch 23 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[24,  1558] loss: 5.046\n",
      "Epoch 24 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[25,  1558] loss: 5.039\n",
      "Epoch 25 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[26,  1558] loss: 5.056\n",
      "Epoch 26 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[27,  1558] loss: 5.043\n",
      "Epoch 27 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 64 %\n",
      "[28,  1558] loss: 5.061\n",
      "Epoch 28 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[29,  1558] loss: 5.032\n",
      "Epoch 29 finished Training.\n",
      "Accuracy of the network on the training: 59 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[30,  1558] loss: 5.050\n",
      "Epoch 30 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[31,  1558] loss: 5.035\n",
      "Epoch 31 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 64 %\n",
      "[32,  1558] loss: 5.040\n",
      "Epoch 32 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[33,  1558] loss: 5.035\n",
      "Epoch 33 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[34,  1558] loss: 5.045\n",
      "Epoch 34 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[35,  1558] loss: 5.039\n",
      "Epoch 35 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[36,  1558] loss: 5.044\n",
      "Epoch 36 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[37,  1558] loss: 5.043\n",
      "Epoch 37 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[38,  1558] loss: 5.050\n",
      "Epoch 38 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[39,  1558] loss: 5.017\n",
      "Epoch 39 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[40,  1558] loss: 5.026\n",
      "Epoch 40 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 64 %\n",
      "[41,  1558] loss: 5.013\n",
      "Epoch 41 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[42,  1558] loss: 5.021\n",
      "Epoch 42 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[43,  1558] loss: 5.017\n",
      "Epoch 43 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[44,  1558] loss: 5.011\n",
      "Epoch 44 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[45,  1558] loss: 5.009\n",
      "Epoch 45 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[46,  1558] loss: 5.020\n",
      "Epoch 46 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[47,  1558] loss: 5.029\n",
      "Epoch 47 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[48,  1558] loss: 5.037\n",
      "Epoch 48 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[49,  1558] loss: 5.032\n",
      "Epoch 49 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 65 %\n",
      "[50,  1558] loss: 5.037\n",
      "Epoch 50 finished Training.\n",
      "Accuracy of the network on the training: 60 %\n",
      "Accuracy of the network on the validation: 60 %\n",
      "[51,  1558] loss: 5.037\n",
      "Epoch 51 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[52,  1558] loss: 5.047\n",
      "Epoch 52 finished Training.\n",
      "Accuracy of the network on the training: 60 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[53,  1558] loss: 5.029\n",
      "Epoch 53 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[54,  1558] loss: 5.031\n",
      "Epoch 54 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[55,  1558] loss: 5.021\n",
      "Epoch 55 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[56,  1558] loss: 5.029\n",
      "Epoch 56 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[57,  1558] loss: 5.021\n",
      "Epoch 57 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 66 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58,  1558] loss: 5.012\n",
      "Epoch 58 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[59,  1558] loss: 5.013\n",
      "Epoch 59 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[60,  1558] loss: 5.023\n",
      "Epoch 60 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[61,  1558] loss: 5.022\n",
      "Epoch 61 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[62,  1558] loss: 5.032\n",
      "Epoch 62 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[63,  1558] loss: 5.027\n",
      "Epoch 63 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[64,  1558] loss: 5.019\n",
      "Epoch 64 finished Training.\n",
      "Accuracy of the network on the training: 61 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[65,  1558] loss: 5.048\n",
      "Epoch 65 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 61 %\n",
      "[66,  1558] loss: 5.028\n",
      "Epoch 66 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[67,  1558] loss: 5.026\n",
      "Epoch 67 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[68,  1558] loss: 5.022\n",
      "Epoch 68 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[69,  1558] loss: 5.022\n",
      "Epoch 69 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[70,  1558] loss: 5.007\n",
      "Epoch 70 finished Training.\n",
      "Accuracy of the network on the training: 64 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[71,  1558] loss: 5.012\n",
      "Epoch 71 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[72,  1558] loss: 5.014\n",
      "Epoch 72 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[73,  1558] loss: 5.005\n",
      "Epoch 73 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[74,  1558] loss: 5.028\n",
      "Epoch 74 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 64 %\n",
      "[75,  1558] loss: 5.030\n",
      "Epoch 75 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[76,  1558] loss: 5.000\n",
      "Epoch 76 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[77,  1558] loss: 5.012\n",
      "Epoch 77 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[78,  1558] loss: 5.029\n",
      "Epoch 78 finished Training.\n",
      "Accuracy of the network on the training: 64 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[79,  1558] loss: 5.016\n",
      "Epoch 79 finished Training.\n",
      "Accuracy of the network on the training: 64 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[80,  1558] loss: 5.018\n",
      "Epoch 80 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[81,  1558] loss: 5.026\n",
      "Epoch 81 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 63 %\n",
      "[82,  1558] loss: 5.010\n",
      "Epoch 82 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[83,  1558] loss: 5.007\n",
      "Epoch 83 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[84,  1558] loss: 5.009\n",
      "Epoch 84 finished Training.\n",
      "Accuracy of the network on the training: 64 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[85,  1558] loss: 5.015\n",
      "Epoch 85 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[86,  1558] loss: 5.010\n",
      "Epoch 86 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 65 %\n",
      "[87,  1558] loss: 5.008\n",
      "Epoch 87 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[88,  1558] loss: 5.005\n",
      "Epoch 88 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[89,  1558] loss: 5.005\n",
      "Epoch 89 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[90,  1558] loss: 5.004\n",
      "Epoch 90 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[91,  1558] loss: 5.004\n",
      "Epoch 91 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[92,  1558] loss: 5.007\n",
      "Epoch 92 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 68 %\n",
      "[93,  1558] loss: 5.002\n",
      "Epoch 93 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[94,  1558] loss: 5.028\n",
      "Epoch 94 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[95,  1558] loss: 5.021\n",
      "Epoch 95 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[96,  1558] loss: 5.005\n",
      "Epoch 96 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 66 %\n",
      "[97,  1558] loss: 5.004\n",
      "Epoch 97 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[98,  1558] loss: 5.002\n",
      "Epoch 98 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 67 %\n",
      "[99,  1558] loss: 5.009\n",
      "Epoch 99 finished Training.\n",
      "Accuracy of the network on the training: 62 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "[100,  1558] loss: 5.004\n",
      "Epoch 100 finished Training.\n",
      "Accuracy of the network on the training: 63 %\n",
      "Accuracy of the network on the validation: 62 %\n",
      "Traininig all done\n"
     ]
    }
   ],
   "source": [
    "n_training = X_train.shape[0]\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "n_validation = X_val.shape[0]\n",
    "X_validation_tensor = torch.from_numpy(X_val).float()\n",
    "y_validation_tensor = torch.from_numpy(y_val).float()\n",
    "n_test = X_test.shape[0]\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()\n",
    "\n",
    "epoches = []\n",
    "training_acc = []\n",
    "val_acc = []\n",
    "\n",
    "epoch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# set up the NN\n",
    "net = Net()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(epoch_size):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(n_training):\n",
    "        # get the inputs\n",
    "        inputs = X_train_tensor[i][:]\n",
    "        labels = y_train_tensor[i]\n",
    "        labels = labels.view(1, -1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        # print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_training == (n_training - 1):    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "    print('Epoch %d finished Training.' %(epoch + 1))\n",
    "    \n",
    "    correct_training = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_training):\n",
    "            inputs = X_train_tensor[i][:]\n",
    "            labels = y_train_tensor[i]\n",
    "            labels = labels.view(1, -1)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            if outputs.data >= 0.5:\n",
    "                predicted = 1\n",
    "            else:\n",
    "                predicted = 0\n",
    "            correct_training += (predicted == labels).item()\n",
    "    print('Accuracy of the network on the training: %d %%' % (\n",
    "        100 * correct_training / n_training))\n",
    "    training_acc.append(correct_training / n_training)\n",
    "\n",
    "    correct_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_validation):\n",
    "            inputs = X_validation_tensor[i][:]\n",
    "            labels = y_validation_tensor[i]\n",
    "            labels = labels.view(1, -1)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            if outputs.data >= 0.5:\n",
    "                predicted = 1\n",
    "            else:\n",
    "                predicted = 0\n",
    "            correct_val += (predicted == labels).item()\n",
    "    print('Accuracy of the network on the validation: %d %%' % (\n",
    "        100 * correct_val / n_validation))\n",
    "    val_acc.append(correct_val / n_validation)\n",
    "    epoches.append(epoch + 1)\n",
    "print('Traininig all done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQARERG1fgHessAbMQZk6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f023160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(epoches, training_acc, linewidth = 2, label = 'Train accuracy rate')\n",
    "plt.plot(epoches, val_acc, linewidth = 2, label='Validation accuracy rate')\n",
    "plt.title('Accuracy Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.xlim([0, epoch_size])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.savefig('nn_acc_update.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the validation: 64 %\n",
      "38 59\n"
     ]
    }
   ],
   "source": [
    "correct_test = 0\n",
    "y_pred = []\n",
    "y_pred1 = []\n",
    "y_true1 = []\n",
    "with torch.no_grad():\n",
    "    for i in range(n_test):\n",
    "        inputs = X_test_tensor[i][:]\n",
    "        labels = y_test_tensor[i]\n",
    "        labels = labels.view(1, -1)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        y_pred.append(outputs.data)\n",
    "        if outputs.data >= 0.5:\n",
    "            predicted = 1\n",
    "        else:\n",
    "            predicted = 0\n",
    "        correct_test += (predicted == labels).item()\n",
    "print('Accuracy of the network on the test: %d %%' % (\n",
    "    100 * correct_test / n_test))\n",
    "print(correct_test, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7628915933898056\n"
     ]
    }
   ],
   "source": [
    "# calculate the AP score\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_pred = np.array(y_pred)\n",
    "ap = average_precision_score(y_test, y_pred)\n",
    "print(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
